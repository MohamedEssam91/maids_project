{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Importing Libraries Needed***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries to get the models that we will use to train and predict and measure performance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Reading Training Data and Pre-Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"train_maids.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the null values with mean\n",
    "for i in df.columns:\n",
    "    df[i].fillna(df[i].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X = df['ram'].values.reshape(-1, 1)  # Accuracy was really low compared when using every column in the dataset or chosen columns\n",
    "# X = df.drop(columns=['price_range'])\n",
    "\n",
    "X = df[['battery_power', 'px_height', 'px_width', 'ram']] # All other data points are low-correlated with target variable shown in EDA, therefore using only 'battery_power', 'px_height', 'px_width', 'ram' column for training\n",
    "y = df['price_range']  # Target variable\n",
    "\n",
    "STDscaler = StandardScaler()\n",
    "# minmaxscaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X = STDscaler.fit_transform(X)\n",
    "# X = minmaxscaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Defining Models and setting hyperparameters for the best accuracy***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Logistic Regression\": LogisticRegression(C = 0.001),\n",
    "          \"K-Nearest Neighbors\": KNeighborsClassifier(weights = \"distance\"),\n",
    "          \"Decision Tree\": DecisionTreeClassifier(),\n",
    "          \"Neural Network\": MLPClassifier(max_iter= 1000, hidden_layer_sizes=(150,)),\n",
    "          \"Random Forest\": RandomForestClassifier(n_estimators = 100, n_jobs = 8, max_samples = 75),\n",
    "          \"Gradient Boosting\": GradientBoostingClassifier(learning_rate= 0.001, max_depth= 6, n_estimators= 150, subsample= 0.8),\n",
    "          \"Ada Boost\" : AdaBoostClassifier(),\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training ML Models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression trained.\n",
      "K-Nearest Neighbors trained.\n",
      "Decision Tree trained.\n",
      "Neural Network trained.\n",
      "Random Forest trained.\n",
      "Gradient Boosting trained.\n",
      "Ada Boost trained.\n"
     ]
    }
   ],
   "source": [
    "model_rf = []\n",
    "for name, model in models.items():    \n",
    "    model_rf.append(model.fit(X_train, y_train))\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Seeing Models Evaluation to choose the best ML Model on the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 75.75%\n",
      "\n",
      "K-Nearest Neighbors: 92.00%\n",
      "\n",
      "Decision Tree: 87.25%\n",
      "\n",
      "Neural Network: 96.50%\n",
      "\n",
      "Random Forest: 86.00%\n",
      "\n",
      "Gradient Boosting: 87.75%\n",
      "\n",
      "Ada Boost: 62.75%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test each model accuracy\n",
    "for name, model in models.items():\n",
    "    print(name + \": {:.2f}%\".format(model.score(X_test, y_test) * 100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       105\n",
      "           1       0.80      0.44      0.57        91\n",
      "           2       0.74      0.50      0.60        92\n",
      "           3       0.76      1.00      0.86       112\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.76      0.73      0.72       400\n",
      "weighted avg       0.76      0.76      0.73       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105   0   0   0]\n",
      " [ 35  40  16   0]\n",
      " [  0  10  46  36]\n",
      " [  0   0   0 112]]\n",
      "Recall Score: 75.75\n",
      "Precision Score: 76.141\n",
      "\n",
      "\n",
      "K-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       105\n",
      "           1       0.89      0.93      0.91        91\n",
      "           2       0.85      0.88      0.87        92\n",
      "           3       0.96      0.90      0.93       112\n",
      "\n",
      "    accuracy                           0.92       400\n",
      "   macro avg       0.92      0.92      0.92       400\n",
      "weighted avg       0.92      0.92      0.92       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[101   4   0   0]\n",
      " [  3  85   3   0]\n",
      " [  0   7  81   4]\n",
      " [  0   0  11 101]]\n",
      "Recall Score: 92.0\n",
      "Precision Score: 92.18\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       105\n",
      "           1       0.79      0.87      0.83        91\n",
      "           2       0.82      0.79      0.81        92\n",
      "           3       0.92      0.92      0.92       112\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.87      0.87      0.87       400\n",
      "weighted avg       0.88      0.87      0.87       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 94  11   0   0]\n",
      " [  5  79   7   0]\n",
      " [  0  10  73   9]\n",
      " [  0   0   9 103]]\n",
      "Recall Score: 87.25\n",
      "Precision Score: 87.512\n",
      "\n",
      "\n",
      "Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       105\n",
      "           1       0.95      0.98      0.96        91\n",
      "           2       0.95      0.93      0.94        92\n",
      "           3       0.97      0.96      0.97       112\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.97      0.96      0.97       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103   2   0   0]\n",
      " [  1  89   1   0]\n",
      " [  0   3  86   3]\n",
      " [  0   0   4 108]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 96.5\n",
      "Precision Score: 96.517\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       105\n",
      "           1       0.85      0.84      0.84        91\n",
      "           2       0.74      0.83      0.78        92\n",
      "           3       0.91      0.83      0.87       112\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[99  6  0  0]\n",
      " [ 7 76  8  0]\n",
      " [ 0  7 76  9]\n",
      " [ 0  0 19 93]]\n",
      "Recall Score: 86.0\n",
      "Precision Score: 86.444\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       105\n",
      "           1       0.82      0.91      0.86        91\n",
      "           2       0.79      0.85      0.82        92\n",
      "           3       0.93      0.86      0.89       112\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[94 11  0  0]\n",
      " [ 3 83  5  0]\n",
      " [ 0  7 78  7]\n",
      " [ 0  0 16 96]]\n",
      "Recall Score: 87.75\n",
      "Precision Score: 88.352\n",
      "\n",
      "\n",
      "Ada Boost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.35      0.50       105\n",
      "           1       0.49      0.80      0.61        91\n",
      "           2       0.56      0.87      0.68        92\n",
      "           3       0.95      0.54      0.69       112\n",
      "\n",
      "    accuracy                           0.63       400\n",
      "   macro avg       0.71      0.64      0.62       400\n",
      "weighted avg       0.73      0.63      0.62       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37 68  0  0]\n",
      " [ 6 73 12  0]\n",
      " [ 0  9 80  3]\n",
      " [ 0  0 51 61]]\n",
      "Recall Score: 62.75\n",
      "Precision Score: 73.214\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    y_predict = model.predict(X_test)\n",
    "    y_predict_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    print(name + \":\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_predict))\n",
    "    print(\"Recall Score:\", round(metrics.recall_score(y_test, y_predict, average='weighted') * 100, 3))\n",
    "    print(\"Precision Score:\", round(metrics.precision_score(y_test, y_predict, average='weighted') * 100, 3))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Choosing K-Nearest Neighbors to avoid over-fitting from Neural Network***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Testing on Test Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess the data from the test dataset\n",
    "df_test = pd.read_excel('test_maids.xlsx')\n",
    "\n",
    "for i in df_test.columns:\n",
    "    df_test[i].fillna(df_test[i].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10_rows = df_test.head(10).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = first_10_rows.drop(labels='id', axis = 1)\n",
    "test_x = test_x[['battery_power', 'px_height', 'px_width', 'ram']]\n",
    "\n",
    "STDscaler = StandardScaler()\n",
    "test_x = STDscaler.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = first_10_rows.copy()\n",
    "df_predict['price_range_prediction'] = model_rf[1].predict(test_x)\n",
    "\n",
    "df_predict.to_excel('prediction_maids.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
